<?xml version="1.0" encoding="UTF-8"?>
<unit><root><base><html src="index.html"><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></html></base>Uq_mt</root><digest>9c171e79d90169806336d502364d1bd2</digest><import>Bigarray<digest>0643187a8b562858118690c393d01c2e</digest></import><import>Buffer<digest>a579f4a57e300ec755f84af883c1e51b</digest></import><import>CamlinternalFormatBasics<digest>ba1be62eb45abd435c75cb59cc46b922</digest></import><import>CamlinternalOO<digest>3d0b4eb4525ba4274c8885d7124f7bbc</digest></import><import>Complex<digest>d0dcc1da3c694cf9a7e924c7832d1528</digest></import><import>Equeue<digest>207ed21b384dd4f4ad91bce8a449f64c</digest></import><import>Hashtbl<digest>bb8e269d690301a1c4ff14a08e96e83e</digest></import><import>Int32<digest>f43b8a2972804b40e28b661b6fdf157a</digest></import><import>Int64<digest>3565b288ec68024088360805650448dd</digest></import><import>Lexing<digest>1be6a5484fb3cfb69d2c981438a7be62</digest></import><import>Netbuffer<digest>5f4225f2baeef1584e246c6ce1d32119</digest></import><import>Netchannels<digest>4e22bd1ba0cae4bd9bd1b6e69fc16ade</digest></import><import>Netexn<digest>845c6110cc81d957d9fc21c9e149d5fb</digest></import><import>Netlog<digest>2441459e41ceb77fc72d5714e0508958</digest></import><import>Netsockaddr<digest>514bc9294568dc3facaf49b96623c337</digest></import><import>Netsys<digest>4a0ae4cc74f10e8667e3b629e6907079</digest></import><import>Netsys_mem<digest>f19ef786301a8cbcfbf1a4fffee992f8</digest></import><import>Netsys_posix<digest>f5b674538a41e016bb4f0e731d114657</digest></import><import>Netsys_signal<digest>703311022efc5162433d614b9bef35af</digest></import><import>Netsys_types<digest>67b26630eaf4decaa483864d4d00a3a2</digest></import><import>Netsys_win32<digest>02161f9169b76f686b05a51ed2d9357c</digest></import><import>Obj<digest>825c406ee2d12ed12fd12dc0e4de1d26</digest></import><import>Oo<digest>0977563fa9c23f2df2952b302bdba835</digest></import><import>Pervasives<digest>0d015a5a2136659b0de431be7f1545be</digest></import><import>Printf<digest>eb49a17645c5ea2dd298430a3c986186</digest></import><import>Set<digest>487197ccd2fea64d52f1cd917061caf2</digest></import><import>Stream<digest>55948988e71c3ee1749feb21ccec9fc9</digest></import><import>Sys<digest>0ce699458ce4430954d7e6a78874647c</digest></import><import>Unix<digest>30a4cc8e5f4f902ea609c91caec48af7</digest></import><import>Unixqueue<digest>5ec5f57d46c5b3e908696c79a59232d4</digest></import><import>Unixqueue_util<digest>f013da7473123405a6e2f9edc5dde5e1</digest></import><import>Uq_engines<digest>7eabb27fa86d9290a1fe2ef78547b48a</digest></import><source><file>uq_mt.mli</file><dir>/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue</dir><digest>38b9668a15ffe529f4c6ee16c02fbec3</digest></source><doc><title level="1">Using engines in multi-threaded programs</title></doc><comment>Monitors can be used to coordinate access to a resource from several
threads so that only one thread comes into contact with the resource.
Of course, the resources we talk about must have an engine interface.
For example, the resource could be an RPC client. In contrast to a
critical section (protected with mutexes), the accesses are not
serialized, but simply pushed onto the same event system, and run
there concurrently. Effectively, the monitor translates heavy-weight
threading (kernel threads) into light-weight threading (engines).</comment><type><type><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor</type><doc>A thread monitor governs which threads have access to a set
of engines running together on an event system</doc></type><value><value><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>create_monitor</value><doc>Creates a new monitor. The passed event system becomes the
inner event system of the monitor. All engines attached to
the monitor will use this event system.</doc><arrow><path><resolved><class_type><identifier><root><base><xml src="../../../../ocamlnet.3.7.7/src/equeue/unixqueue/index.xml"><cmti name="Unixqueue" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/unixqueue.cmti" digest="5ec5f57d46c5b3e908696c79a59232d4"/></xml></base>Unixqueue</root></identifier>event_system</class_type></resolved></path><path><resolved><identifier><type><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor</type></identifier></resolved></path></arrow></value><value><value><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor_run</value><doc><code>let result = monitor_run mon f outer_esys arg</code>:
Runs another engine within the
monitor. The engine <code>inner_e</code> is created as<newline/><precode>let inner_e = f inner_esys arg</precode><newline/>where <code>inner_esys</code> is the event system of the monitor. It is
obligatory that <code>inner_e</code> uses this event system.<newline/>When <code>inner_e</code> reaches a final state, the thread leaves the
monitor, and the result of <code>inner_e</code> is returned (or the
recorded exception is thrown).<newline/>The &quot;special effect&quot; of the monitor is that several threads can
share the same monitor, even at the same time. All parallel running
engines <code>inner_e</code> will use the same event system <code>inner_esys</code>.
Of course, this also means that they run in the same thread.
Note that it is possible that the monitor switches the thread
it uses for executing the event system (and the engines). In
particular, this can happen when one of the inner engines finishes,
and the thread that put this engine into the monitor was chosen
as the thread for executing the event system. When this happens,
another thread waiting for the monitor will be selected for
running the event system.<newline/>If an inner engine establishes configurations that are not bound
to the lifetime of the inner engine, there is no guarantee that
these additional events and handlers will be considered when the
inner engine ends. For example, if the engine starts a timer to
run an action later, it is not said that the action is carried
out at all if the engine terminates before.<newline/>Exceptions falling through to the caller of the event system
are logged and otherwise ignored.<newline/>It is possible to use monitors in single-threaded programs -
this is treated as if only one thread was using the monitor in a
multi-threaded program.</doc><arrow><path><resolved><identifier><type><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor</type></identifier></resolved></path><arrow><arrow><path><resolved><class_type><identifier><root><base><xml src="../../../../ocamlnet.3.7.7/src/equeue/unixqueue/index.xml"><cmti name="Unixqueue" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/unixqueue.cmti" digest="5ec5f57d46c5b3e908696c79a59232d4"/></xml></base>Unixqueue</root></identifier>event_system</class_type></resolved></path><arrow><var>a</var><path><resolved><class_type><identifier><root><base><xml src="../../../../ocamlnet.3.7.7/src/equeue/uq_engines/index.xml"><cmti name="Uq_engines" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_engines.cmti" digest="7eabb27fa86d9290a1fe2ef78547b48a"/></xml></base>Uq_engines</root></identifier>engine</class_type></resolved><var>b</var></path></arrow></arrow><arrow><var>a</var><var>b</var></arrow></arrow></arrow></value><value><value><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor_do</value><doc><code>let result = monitor_do mon f arg</code>: Just runs <code>f arg</code> in the
scope of the monitor, and returns the result.</doc><arrow><path><resolved><identifier><type><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor</type></identifier></resolved></path><arrow><arrow><var>a</var><var>b</var></arrow><arrow><var>a</var><var>b</var></arrow></arrow></arrow></value><value><value><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor_async</value><doc><code>let result = monitor_async f arg</code>: For calling RPC-style
asynchronous clients. If <code>f</code> is called like <code>f arg emit</code>,
the result is passed back by calling <code>emit (fun () -&gt; result)</code>.</doc><arrow><path><resolved><identifier><type><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>monitor</type></identifier></resolved></path><arrow><arrow><var>a</var><arrow><arrow><arrow><path><resolved><identifier><type>unit</type></identifier></resolved></path><var>b</var></arrow><path><resolved><identifier><type>unit</type></identifier></resolved></path></arrow><path><resolved><identifier><type>unit</type></identifier></resolved></path></arrow></arrow><arrow><var>a</var><var>b</var></arrow></arrow></arrow></value><comment><title level="2"><label><root><base><xml src="index.xml"><cmti name="Uq_mt" src="/home/dsheets/.opam/doc/build/ocamlnet.3.7.7/src/equeue/uq_mt.cmti" digest="9c171e79d90169806336d502364d1bd2"/></xml></base>Uq_mt</root>rpc_client</label>Example: Threads sharing an RPC client</title><newline/>In this example we want to achieve that several threads can use the
same RPC client. This type of client is not thread-safe, but it is
able to run asynchronously. Because of this, the requests coming from
several threads can be concurrently handled.<newline/>Prepare the RPC client and the monitor: We assume that <code>M_clnt</code> is
the generated RPC module with the client, and that we access program
<code>P</code> at version <code>V</code>.<newline/><precode>      let esys = Unixqueue.create_unix_event_system
      let rpc = M_clnt.P.V.create_client ~esys connector protocol
      let mon = Uq_mt.create_monitor esys</precode><newline/>It is essential that the RPC client and the monitor use the same
<code>esys</code>.<newline/>Next, let's assume we are in a spawned thread, and we want to
call an RPC procedure <code>M_clnt.P.V.proc</code>. The trick here is to
use the asynchronous variant <code>M_clnt.P.V.proc'async</code>, and to
call it via the monitor:<newline/><precode>      let result = Uq_mt.monitor_async mon (M_clnt.P.V.proc'async rpc) arg</precode><newline/>The procedure is called with argument <code>arg</code> and returns the <code>result</code>.
The monitor waits until the asynchronous call is done, so this appears
as a synchronous call to the user.<newline/>If you need to call functions to configure and control the RPC
client, use <code>monitor_do</code>:<newline/><precode>      let sockaddr = Uq_mt.monitor_do mon Rpc_client.get_peer_name rpc</precode></comment></unit>